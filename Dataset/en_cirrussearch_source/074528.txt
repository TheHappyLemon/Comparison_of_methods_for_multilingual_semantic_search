Random-access memory (RAM; /ræm/) is a form of electronic computer memory that can be read and changed in any order, typically used to store working data and machine code. A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement. RAM contains multiplexing and demultiplexing circuitry, to connect the data lines to the addressed storage for reading or writing the entry. Usually more than one bit of storage is accessed by the same address, and RAM devices often have multiple data lines and are said to be "8-bit" or "16-bit", etc. devices.[clarification needed] In today's technology, random-access memory takes the form of integrated circuit (IC) chips with MOS (metal–oxide–semiconductor) memory cells. RAM is normally associated with volatile types of memory where stored information is lost if power is removed. The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM). Non-volatile RAM has also been developed and other types of non-volatile memories allow random access for read operations, but either do not allow write operations or have other kinds of limitations on them. These include most types of ROM and a type of flash memory called NOR-Flash. Use of semiconductor RAM dated back to 1965, when IBM introduced the monolithic (single-chip) 16-bit SP95 SRAM chip for their System/360 Model 95 computer, and Toshiba used discrete DRAM memory cells for its 180-bit Toscal BC-1411 electronic calculator, both based on bipolar transistors. While it offered higher speeds than magnetic-core memory, bipolar DRAM could not compete with the lower price of the then-dominant magnetic-core memory. MOS memory, based on MOS transistors, was developed in the late 1960s, and was the basis for all early commercial semiconductor memory. The first commercial DRAM IC chip, the 1K Intel 1103, was introduced in October 1970. Synchronous dynamic random-access memory (SDRAM) later debuted with the Samsung KM48SL2000 chip in 1992. Early computers used relays, mechanical counters or delay lines for main memory functions. Ultrasonic delay lines were serial devices which could only reproduce data in the order it was written. Drum memory could be expanded at relatively low cost but efficient retrieval of memory items requires knowledge of the physical layout of the drum to optimize speed. Latches built out of vacuum tube triodes, and later, out of discrete transistors, were used for smaller and faster memories such as registers. Such registers were relatively large and too costly to use for large amounts of data; generally only a few dozen or few hundred bits of such memory could be provided. The first practical form of random-access memory was the Williams tube starting in 1947. It stored data as electrically charged spots on the face of a cathode-ray tube. Since the electron beam of the CRT could read and write the spots on the tube in any order, memory was random access. The capacity of the Williams tube was a few hundred to around a thousand bits, but it was much smaller, faster, and more power-efficient than using individual vacuum tube latches. Developed at the University of Manchester in England, the Williams tube provided the medium on which the first electronically stored program was implemented in the Manchester Baby computer, which first successfully ran a program on 21 June, 1948. In fact, rather than the Williams tube memory being designed for the Baby, the Baby was a testbed to demonstrate the reliability of the memory. Magnetic-core memory was invented in 1947 and developed up until the mid-1970s. It became a widespread form of random-access memory, relying on an array of magnetized rings. By changing the sense of each ring's magnetization, data could be stored with one bit stored per ring. Since every ring had a combination of address wires to select and read or write it, access to any memory location in any sequence was possible. Magnetic core memory was the standard form of computer memory system until displaced by solid-state MOS (metal–oxide–silicon) semiconductor memory in integrated circuits (ICs) during the early 1970s. Prior to the development of integrated read-only memory (ROM) circuits, permanent (or read-only) random-access memory was often constructed using diode matrices driven by address decoders, or specially wound core rope memory planes.[citation needed] Semiconductor memory began in the 1960s with bipolar memory, which used bipolar transistors. Although it was faster, it could not compete with the lower price of magnetic core memory. The invention of the MOSFET (metal–oxide–semiconductor field-effect transistor), also known as the MOS transistor, by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959, led to the development of metal–oxide–semiconductor (MOS) memory by John Schmidt at Fairchild Semiconductor in 1964. In addition to higher speeds, MOS semiconductor memory was cheaper and consumed less power than magnetic core memory. The development of silicon-gate MOS integrated circuit (MOS IC) technology by Federico Faggin at Fairchild in 1968 enabled the production of MOS memory chips. MOS memory overtook magnetic core memory as the dominant memory technology in the early 1970s. An integrated bipolar static random-access memory (SRAM) was invented by Robert H. Norman at Fairchild Semiconductor in 1963. It was followed by the development of MOS SRAM by John Schmidt at Fairchild in 1964. SRAM became an alternative to magnetic-core memory, but required six MOS transistors for each bit of data. Commercial use of SRAM began in 1965, when IBM introduced the SP95 memory chip for the System/360 Model 95. Dynamic random-access memory (DRAM) allowed replacement of a 4 or 6-transistor latch circuit by a single transistor for each memory bit, greatly increasing memory density at the cost of volatility. Data was stored in the tiny capacitance of each transistor, and had to be periodically refreshed every few milliseconds before the charge could leak away. Toshiba's Toscal BC-1411 electronic calculator, which was introduced in 1965, used a form of capacitive bipolar DRAM, storing 180-bit data on discrete memory cells, consisting of germanium bipolar transistors and capacitors. While it offered higher speeds than magnetic-core memory, bipolar DRAM could not compete with the lower price of the then dominant magnetic-core memory. MOS technology is the basis for modern DRAM. In 1966, Dr. Robert H. Dennard at the IBM Thomas J. Watson Research Center was working on MOS memory. While examining the characteristics of MOS technology, he found it was capable of building capacitors, and that storing a charge or no charge on the MOS capacitor could represent the 1 and 0 of a bit, while the MOS transistor could control writing the charge to the capacitor. This led to his development of a single-transistor DRAM memory cell. In 1967, Dennard filed a patent under IBM for a single-transistor DRAM memory cell, based on MOS technology. The first commercial DRAM IC chip was the Intel 1103, which was manufactured on an 8 μm MOS process with a capacity of 1 kbit, and was released in 1970. Synchronous dynamic random-access memory (SDRAM) was developed by Samsung Electronics. The first commercial SDRAM chip was the Samsung KM48SL2000, which had a capacity of 16 Mbit. It was introduced by Samsung in 1992, and mass-produced in 1993. The first commercial DDR SDRAM (double data rate SDRAM) memory chip was Samsung's 64 Mbit DDR SDRAM chip, released in June 1998. GDDR (graphics DDR) is a form of DDR SGRAM (synchronous graphics RAM), which was first released by Samsung as a 16 Mbit memory chip in 1998. The two widely used forms of modern RAM are static RAM (SRAM) and dynamic RAM (DRAM). In SRAM, a bit of data is stored using the state of a six-transistor memory cell, typically using six MOSFETs. This form of RAM is more expensive to produce, but is generally faster and requires less dynamic power than DRAM. In modern computers, SRAM is often used as cache memory for the CPU. DRAM stores a bit of data using a transistor and capacitor pair (typically a MOSFET and MOS capacitor, respectively), which together comprise a DRAM cell. The capacitor holds a high or low charge (1 or 0, respectively), and the transistor acts as a switch that lets the control circuitry on the chip read the capacitor's state of charge or change it. As this form of memory is less expensive to produce than static RAM, it is the predominant form of computer memory used in modern computers. Both static and dynamic RAM are considered volatile, as their state is lost or reset when power is removed from the system. By contrast, read-only memory (ROM) stores data by permanently enabling or disabling selected transistors, such that the memory cannot be altered. Writable variants of ROM (such as EEPROM and NOR flash) share properties of both ROM and RAM, enabling data to persist without power and to be updated without requiring special equipment. ECC memory (which can be either SRAM or DRAM) includes special circuitry to detect and/or correct random faults (memory errors) in the stored data, using parity bits or error correction codes. In general, the term RAM refers solely to solid-state memory devices (either DRAM or SRAM), and more specifically the main memory in most computers. In optical storage, the term DVD-RAM is somewhat of a misnomer since, it is not random access; it behaves much like a hard disc drive if somewhat slower. Aside, unlike CD-RW or DVD-RW, DVD-RAM does not need to be erased before reuse. The memory cell is the fundamental building block of computer memory. The memory cell is an electronic circuit that stores one bit of binary information and it must be set to store a logic 1 (high voltage level) and reset to store a logic 0 (low voltage level). Its value is maintained/stored until it is changed by the set/reset process. The value in the memory cell can be accessed by reading it. In SRAM, the memory cell is a type of flip-flop circuit, usually implemented using FETs. This means that SRAM requires very low power when not being accessed, but it is expensive and has low storage density. A second type, DRAM, is based around a capacitor. Charging and discharging this capacitor can store a "1" or a "0" in the cell. However, the charge in this capacitor slowly leaks away, and must be refreshed periodically. Because of this refresh process, DRAM uses more power, but it can achieve greater storage densities and lower unit costs compared to SRAM. To be useful, memory cells must be readable and writable. Within the RAM device, multiplexing and demultiplexing circuitry is used to select memory cells. Typically, a RAM device has a set of address lines A0,A1,...An{\displaystyle A_{0},A_{1},...A_{n}}, and for each combination of bits that may be applied to these lines, a set of memory cells are activated. Due to this addressing, RAM devices virtually always have a memory capacity that is a power of two. Usually several memory cells share the same address. For example, a 4 bit 'wide' RAM chip has 4 memory cells for each address. Often the width of the memory and that of the microprocessor are different, for a 32 bit microprocessor, eight 4 bit RAM chips would be needed. Often more addresses are needed than can be provided by a device. In that case, external multiplexors to the device are used to activate the correct device that is being accessed. One can read and over-write data in RAM. Many computer systems have a memory hierarchy consisting of processor registers, on-die SRAM caches, external caches, DRAM, paging systems and virtual memory or swap space on a hard drive. This entire pool of memory may be referred to as "RAM" by many developers, even though the various subsystems can have very different access times, violating the original concept behind the random access term in RAM. Even within a hierarchy level such as DRAM, the specific row, column, bank, rank, channel, or interleave organization of the components make the access time variable, although not to the extent that access time to rotating storage media or a tape is variable. The overall goal of using a memory hierarchy is to obtain the fastest possible average access time while minimizing the total cost of the entire memory system (generally, the memory hierarchy follows the access time with the fast CPU registers at the top and the slow hard drive at the bottom). In many modern personal computers, the RAM comes in an easily upgraded form of modules called memory modules or DRAM modules about the size of a few sticks of chewing gum. These can be quickly replaced should they become damaged or when changing needs demand more storage capacity. As suggested above, smaller amounts of RAM (mostly SRAM) are also integrated in the CPU and other ICs on the motherboard, as well as in hard-drives, CD-ROMs, and several other parts of the computer system. In addition to serving as temporary storage and working space for the operating system and applications, RAM is used in numerous other ways. Most modern operating systems employ a method of extending RAM capacity, known as "virtual memory". A portion of the computer's hard drive is set aside for a paging file or a scratch partition, and the combination of physical RAM and the paging file form the system's total memory. (For example, if a computer has 2 GB (10243 B) of RAM and a 1 GB page file, the operating system has 3 GB total memory available to it.) When the system runs low on physical memory, it can "swap" portions of RAM to the paging file to make room for new data, as well as to read previously swapped information back into RAM. Excessive use of this mechanism results in thrashing and generally hampers overall system performance, mainly because hard drives are far slower than RAM. Software can "partition" a portion of a computer's RAM, allowing it to act as a much faster hard drive that is called a RAM disk. A RAM disk loses the stored data when the computer is shut down, unless memory is arranged to have a standby battery source, or changes to the RAM disk are written out to a nonvolatile disk. The RAM disk is reloaded from the physical disk upon RAM disk initialization. Sometimes, the contents of a relatively slow ROM chip are copied to read/write memory to allow for shorter access times. The ROM chip is then disabled while the initialized memory locations are switched in on the same block of addresses (often write-protected). This process, sometimes called shadowing, is fairly common in both computers and embedded systems. As a common example, the BIOS in typical personal computers often has an option called "use shadow BIOS" or similar. When enabled, functions that rely on data from the BIOS's ROM instead use DRAM locations (most can also toggle shadowing of video card ROM or other ROM sections). Depending on the system, this may not result in increased performance, and may cause incompatibilities. For example, some hardware may be inaccessible to the operating system if shadow RAM is used. On some systems the benefit may be hypothetical because the BIOS is not used after booting in favor of direct hardware access. Free memory is reduced by the size of the shadowed ROMs. The "memory wall" is the growing disparity of speed between CPU and the response time of memory (known as memory latency) outside the CPU chip. An important reason for this disparity is the limited communication bandwidth beyond chip boundaries, which is also referred to as bandwidth wall. From 1986 to 2000, CPU speed improved at an annual rate of 55% while off-chip memory response time only improved at 10%. Given these trends, it was expected that memory latency would become an overwhelming bottleneck in computer performance. Another reason for the disparity is the enormous increase in the size of memory since the start of the PC revolution in the 1980s. Originally, PCs contained less than 1 mebibyte of RAM, which often had a response time of 1 CPU clock cycle, meaning that it required 0 wait states. Larger memory units are inherently slower than smaller ones of the same type, simply because it takes longer for signals to traverse a larger circuit. Constructing a memory unit of many gibibytes with a response time of one clock cycle is difficult or impossible. Today's CPUs often still have a mebibyte of 0 wait state cache memory, but it resides on the same chip as the CPU cores due to the bandwidth limitations of chip-to-chip communication. It must also be constructed from static RAM, which is far more expensive than the dynamic RAM used for larger memories. Static RAM also consumes far more power. CPU speed improvements slowed significantly partly due to major physical barriers and partly because current CPU designs have already hit the memory wall in some sense. Intel summarized these causes in a 2005 document. First of all, as chip geometries shrink and clock frequencies rise, the transistor leakage current increases, leading to excess power consumption and heat... Secondly, the advantages of higher clock speeds are in part negated by memory latency, since memory access times have not been able to keep pace with increasing clock frequencies. Third, for certain applications, traditional serial architectures are becoming less efficient as processors get faster (due to the so-called Von Neumann bottleneck), further undercutting any gains that frequency increases might otherwise buy. In addition, partly due to limitations in the means of producing inductance within solid state devices, resistance-capacitance (RC) delays in signal transmission are growing as feature sizes shrink, imposing an additional bottleneck that frequency increases don't address. The RC delays in signal transmission were also noted in "Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures" which projected a maximum of 12.5% average annual CPU performance improvement between 2000 and 2014. A different concept is the processor-memory performance gap, which can be addressed by 3D integrated circuits that reduce the distance between the logic and memory aspects that are further apart in a 2D chip. Memory subsystem design requires a focus on the gap, which is widening over time. The main method of bridging the gap is the use of caches; small amounts of high-speed memory that houses recent operations and instructions nearby the processor, speeding up the execution of those operations or instructions in cases where they are called upon frequently. Multiple levels of caching have been developed to deal with the widening gap, and the performance of high-speed modern computers relies on evolving caching techniques. There can be up to a 53% difference between the growth in speed of processor and the lagging speed of main memory access. Solid-state hard drives have continued to increase in speed, from ~400 Mbit/s via SATA3 in 2012 up to ~3 GB/s via NVMe/PCIe in 2018, closing the gap between RAM and hard disk speeds, although RAM continues to be an order of magnitude faster, with single-lane DDR4 3200 capable of 25 GB/s, and modern GDDR even faster. Fast, cheap, non-volatile solid state drives have replaced some functions formerly performed by RAM, such as holding certain data for immediate availability in server farms - 1 terabyte of SSD storage can be had for $200, while 1 TB of RAM would cost thousands of dollars. Technology portal CAS latency (CL) Hybrid Memory Cube Multi-channel memory architecture Registered/buffered memory RAM parity Memory Interconnect/RAM buses Memory geometry Chip creep Read-mostly memory (RMM) Electrochemical random-access memory "RAM". Cambridge English Dictionary. Retrieved 11 July 2019. "RAM". Oxford Advanced Learner's Dictionary. Retrieved 11 July 2019. Gallagher, Sean (April 4, 2013). "Memory that never forgets: non-volatile DIMMs hit the market". Ars Technica. Archived from the original on July 8, 2017. "1966: Semiconductor RAMs Serve High-speed Storage Needs". Computer History Museum. "IBM Archives -- FAQ's for Products and Services". ibm.com. Archived from the original on 2012-10-23. Napper, Brian, Computer 50: The University of Manchester Celebrates the Birth of the Modern Computer, archived from the original on 4 May 2012, retrieved 26 May 2012 Williams, F. C.; Kilburn, T. (Sep 1948), "Electronic Digital Computers", Nature, 162 (4117): 487, Bibcode:1948Natur.162..487W, doi:10.1038/162487a0, S2CID 4110351. Reprinted in The Origins of Digital Computers. Williams, F. C.; Kilburn, T.; Tootill, G. C. (Feb 1951), "Universal High-Speed Digital Computers: A Small-Scale Experimental Machine", Proc. IEE, 98 (61): 13–28, doi:10.1049/pi-2.1951.0004, archived from the original on 2013-11-17. "1970: Semiconductors compete with magnetic cores". Computer History Museum. Retrieved 19 June 2019. "1966: Semiconductor RAMs Serve High-speed Storage Needs". Computer History Museum. Retrieved 19 June 2019. "1960 – Metal Oxide Semiconductor (MOS) Transistor Demonstrated". The Silicon Engine. Computer History Museum. Solid State Design – Vol. 6. Horizon House. 1965. "1968: Silicon Gate Technology Developed for ICs". Computer History Museum. Retrieved 10 August 2019. US patent 3562721, Robert H. Norman, "Solid State Switching and Memory Apparatus", published 9 February1971  "DRAM". IBM100. IBM. 9 August 2017. Retrieved 20 September 2019. Toscal BC-1411 calculator. Archived 2017-07-29 at the Wayback Machine, Science Museum, London. "Spec Sheet for Toshiba "TOSCAL" BC-1411". Old Calculator Web Museum. Archived from the original on 3 July 2017. Retrieved 8 May 2018. Toshiba "Toscal" BC-1411 Desktop Calculator Archived 2007-05-20 at the Wayback Machine "1966: Semiconductor RAMs Serve High-speed Storage Needs". Computer History Museum. "Robert Dennard". Encyclopedia Britannica. Retrieved 8 July 2019. Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. pp. 362–363. ISBN 9783540342588. The i1103 was manufactured on a 6-mask silicon-gate P-MOS process with 8 μm minimum features. The resulting product had a 2,400 μm2 memory cell size, a die size just under 10 mm2, and sold for around $21. Bellis, Mary. "The Invention of the Intel 1103". Archived from the original on 2020-03-14. Retrieved 2015-07-11. "Electronic Design". Electronic Design. 41 (15–21). Hayden Publishing Company. 1993. The first commercial synchronous DRAM, the Samsung 16-Mbit KM48SL2000, employs a single-bank architecture that lets system designers easily transition from asynchronous to synchronous systems. "KM48SL2000-7 Datasheet". Samsung. August 1992. Retrieved 19 June 2019. "Samsung Electronics Develops First 128Mb SDRAM with DDR/SDR Manufacturing Option". Samsung Electronics. Samsung. 10 February 1999. Retrieved 23 June 2019. "Samsung Electronics Comes Out with Super-Fast 16M DDR SGRAMs". Samsung Electronics. Samsung. 17 September 1998. Retrieved 23 June 2019. Sze, Simon M. (2002). Semiconductor Devices: Physics and Technology (PDF) (2nd ed.). Wiley. p. 214. ISBN 0-471-33372-7. "Shadow Ram". Archived from the original on 2006-10-29. Retrieved 2007-07-24. The term was coined in "Archived copy" (PDF). Archived (PDF) from the original on 2012-04-06. Retrieved 2011-12-14.{{cite web}}: CS1 maint: archived copy as title (link). "Platform 2015: Intel Processor and Platform Evolution for the Next Decade" (PDF). March 2, 2005. Archived (PDF) from the original on April 27, 2011. Agarwal, Vikas; Hrishikesh, M. S.; Keckler, Stephen W.; Burger, Doug (June 10–14, 2000). "Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures" (PDF). Proceedings of the 27th Annual International Symposium on Computer Architecture. 27th Annual International Symposium on Computer Architecture. Vancouver, BC. Retrieved 14 July 2018. Rainer Waser (2012). Nanoelectronics and Information Technology. John Wiley & Sons. p. 790. ISBN 9783527409273. Archived from the original on August 1, 2016. Retrieved March 31, 2014. Chris Jesshope and Colin Egan (2006). Advances in Computer Systems Architecture: 11th Asia-Pacific Conference, ACSAC 2006, Shanghai, China, September 6-8, 2006, Proceedings. Springer. p. 109. ISBN 9783540400561. Archived from the original on August 1, 2016. Retrieved March 31, 2014. Ahmed Amine Jerraya and Wayne Wolf (2005). Multiprocessor Systems-on-chips. Morgan Kaufmann. pp. 90–91. ISBN 9780123852519. Archived from the original on August 1, 2016. Retrieved March 31, 2014. Celso C. Ribeiro and Simone L. Martins (2004). Experimental and Efficient Algorithms: Third International Workshop, WEA 2004, Angra Dos Reis, Brazil, May 25-28, 2004, Proceedings, Volume 3. Springer. p. 529. ISBN 9783540220671. Archived from the original on August 1, 2016. Retrieved March 31, 2014. "SSD Prices Continue to Fall, Now Upgrade Your Hard Drive!". MiniTool. 2018-09-03. Retrieved 2019-03-28. Coppock, Mark (31 January 2017). "If you're buying or upgrading your PC, expect to pay more for RAM". www.digitaltrends.com. Retrieved 2019-03-28. IBM first in IC memory. IBM Corporation. 1965. Retrieved 19 June 2019. {{cite book}}: |website= ignored (help) Sah, Chih-Tang (October 1988). "Evolution of the MOS transistor-from conception to VLSI" (PDF). Proceedings of the IEEE. 76 (10): 1280–1326 (1303). Bibcode:1988IEEEP..76.1280S. doi:10.1109/5.16328. ISSN 0018-9219. "Late 1960s: Beginnings of MOS memory" (PDF). Semiconductor History Museum of Japan. 2019-01-23. Retrieved 27 June 2019. "A chronological list of Intel products. The products are sorted by date" (PDF). Intel museum. Intel Corporation. July 2005. Archived from the original (PDF) on August 9, 2007. Retrieved July 31, 2007. "1970s: SRAM evolution" (PDF). Semiconductor History Museum of Japan. Retrieved 27 June 2019. Pimbley, J. (2012). Advanced CMOS Process Technology. Elsevier. p. 7. ISBN 9780323156806. "Intel Memory". Intel Vintage. Archived from the original on 2022-03-19. Retrieved 2019-07-06. Component Data Catalog (PDF). Intel. 1978. p. 3. Retrieved 27 June 2019. "Silicon Gate MOS 2102A". Intel. Retrieved 27 June 2019. "1978: Double-well fast CMOS SRAM (Hitachi)" (PDF). Semiconductor History Museum of Japan. Retrieved 5 July 2019. "Memory". STOL (Semiconductor Technology Online). Retrieved 25 June 2019. Isobe, Mitsuo; Uchida, Yukimasa; Maeguchi, Kenji; Mochizuki, T.; Kimura, M.; Hatano, H.; Mizutani, Y.; Tango, H. (October 1981). "An 18 ns CMOS/SOS 4K static RAM". IEEE Journal of Solid-State Circuits. 16 (5): 460–465. Bibcode:1981IJSSC..16..460I. doi:10.1109/JSSC.1981.1051623. S2CID 12992820. Yoshimoto, M.; Anami, K.; Shinohara, H.; Yoshihara, T.; Takagi, H.; Nagao, S.; Kayano, S.; Nakano, T. (1983). "A 64Kb full CMOS RAM with divided word line structure". 1983 IEEE International Solid-State Circuits Conference. Digest of Technical Papers. Vol. XXVI. pp. 58–59. doi:10.1109/ISSCC.1983.1156503. S2CID 34837669. Havemann, Robert H.; Eklund, R. E.; Tran, Hiep V.; Haken, R. A.; Scott, D. B.; Fung, P. K.; Ham, T. E.; Favreau, D. P.; Virkus, R. L. (December 1987). "An 0.8 μm 256K BiCMOS SRAM technology". 1987 International Electron Devices Meeting. pp. 841–843. doi:10.1109/IEDM.1987.191564. S2CID 40375699. Shahidi, Ghavam G.; Davari, Bijan; Dennard, Robert H.; Anderson, C. A.; Chappell, B. A.; et al. (December 1994). "A room temperature 0.1 μm CMOS on SOI". IEEE Transactions on Electron Devices. 41 (12): 2405–2412. Bibcode:1994ITED...41.2405S. doi:10.1109/16.337456. S2CID 108832941. "Japanese Company Profiles" (PDF). Smithsonian Institution. 1996. Retrieved 27 June 2019. "History: 1990s". SK Hynix. Archived from the original on 5 February 2021. Retrieved 6 July 2019. "Intel: 35 Years of Innovation (1968–2003)" (PDF). Intel. 2003. Retrieved 26 June 2019. The DRAM memory of Robert Dennard history-computer.com "Manufacturers in Japan enter the DRAM market and integration densities are improved" (PDF). Semiconductor History Museum of Japan. Retrieved 27 June 2019. Gealow, Jeffrey Carl (10 August 1990). "Impact of Processing Technology on DRAM Sense Amplifier Design" (PDF). Massachusetts Institute of Technology. pp. 149–166. Retrieved 25 June 2019 – via CORE. "Silicon Gate MOS 2107A". Intel. Retrieved 27 June 2019. "One of the Most Successful 16K Dynamic RAMs: The 4116". National Museum of American History. Smithsonian Institution. Archived from the original on 2023-05-31. Retrieved 20 June 2019. Memory Data Book And Designers Guide (PDF). Mostek. March 1979. pp. 9 & 183. "The Cutting Edge of IC Technology: The First 294,912-Bit (288K) Dynamic RAM". National Museum of American History. Smithsonian Institution. Retrieved 20 June 2019. "Computer History for 1984". Computer Hope. Retrieved 25 June 2019. "Japanese Technical Abstracts". Japanese Technical Abstracts. 2 (3–4). University Microfilms: 161. 1987. The announcement of 1M DRAM in 1984 began the era of megabytes. Robinson, Arthur L. (11 May 1984). "Experimental Memory Chips Reach 1 Megabit: As they become larger, memories become an increasingly important part of the integrated circuit business, technologically and economically". Science. 224 (4649): 590–592. doi:10.1126/science.224.4649.590. ISSN 0036-8075. PMID 17838349. MOS Memory Data Book (PDF). Texas Instruments. 1984. pp. 4–15. Retrieved 21 June 2019. "Famous Graphics Chips: TI TMS34010 and VRAM". IEEE Computer Society. 10 January 2019. Retrieved 29 June 2019. "μPD41264 256K Dual Port Graphics Buffer" (PDF). NEC Electronics. Retrieved 21 June 2019. "Sense amplifier circuit for switching plural inputs at low power". Google Patents. Retrieved 21 June 2019. "Fine CMOS techniques create 1M VSRAM". Japanese Technical Abstracts. 2 (3–4). University Microfilms: 161. 1987. Hanafi, Hussein I.; Lu, Nicky C. C.; Chao, H. H.; Hwang, Wei; Henkels, W. H.; Rajeevakumar, T. V.; Terman, L. M.; Franch, Robert L. (October 1988). "A 20-ns 128-kbit*4 high speed DRAM with 330-Mbit/s data rate". IEEE Journal of Solid-State Circuits. 23 (5): 1140–1149. Bibcode:1988IJSSC..23.1140L. doi:10.1109/4.5936. Breaking the gigabit barrier, DRAMs at ISSCC portend major system-design impact. (dynamic random access memory; International Solid-State Circuits Conference; Hitachi Ltd. and NEC Corp. research and development), January 9, 1995 Scott, J.F. (2003). "Nano-Ferroelectrics". In Tsakalakos, Thomas; Ovid'ko, Ilya A.; Vasudevan, Asuri K. (eds.). Nanostructures: Synthesis, Functional Properties and Application. Springer Science & Business Media. pp. 584–600 (597). ISBN 9789400710191. "Toshiba's new 32 Mb Pseudo-SRAM is no fake". The Engineer. 24 June 2001. Archived from the original on 29 June 2019. Retrieved 29 June 2019. "A Study of the DRAM industry" (PDF). MIT. 8 June 2010. Retrieved 29 June 2019. Here, K, M, G, or T refer to the binary prefixes based on powers of 1024. "KM48SL2000-7 Datasheet". Samsung. August 1992. Retrieved 19 June 2019. "MSM5718C50/MD5764802" (PDF). Oki Semiconductor. February 1999. Archived (PDF) from the original on 2019-06-21. Retrieved 21 June 2019. "Ultra 64 Tech Specs". Next Generation. No. 14. Imagine Media. February 1996. p. 40. "Direct RDRAM" (PDF). Rambus. 12 March 1998. Archived (PDF) from the original on 2019-06-21. Retrieved 21 June 2019. "Samsung Electronics Comes Out with Super-Fast 16M DDR SGRAMs". Samsung Electronics. Samsung. 17 September 1998. Retrieved 23 June 2019. "Samsung Electronics Develops First 128Mb SDRAM with DDR/SDR Manufacturing Option". Samsung Electronics. Samsung. 10 February 1999. Retrieved 23 June 2019. "Samsung Demonstrates World's First DDR 3 Memory Prototype". Phys.org. 17 February 2005. Retrieved 23 June 2019. "History". Samsung Electronics. Samsung. Retrieved 19 June 2019. "EMOTION ENGINE AND GRAPHICS SYNTHESIZER USED IN THE CORE OF PLAYSTATION BECOME ONE CHIP" (PDF). Sony. April 21, 2003. Archived (PDF) from the original on 2017-02-27. Retrieved 26 June 2019. "History: 2000s". az5miao. Retrieved 4 April 2022. "Samsung Develops the Industry's Fastest DDR3 SRAM for High Performance EDP and Network Applications". Samsung Semiconductor. Samsung. 29 January 2003. Retrieved 25 June 2019. "Elpida ships 2GB DDR2 modules". The Inquirer. 4 November 2003. Archived from the original on July 10, 2019. Retrieved 25 June 2019.{{cite news}}: CS1 maint: unfit URL (link) "Samsung Shows Industry's First 2-Gigabit DDR2 SDRAM". Samsung Semiconductor. Samsung. 20 September 2004. Retrieved 25 June 2019. "ソニー、65nm対応の半導体設備を導入。3年間で2,000億円の投資". pc.watch.impress.co.jp. Archived from the original on 2016-08-13. ATI engineers by way of Beyond 3D's Dave Baumann "Our Proud Heritage from 2000 to 2009". Samsung Semiconductor. Samsung. Retrieved 25 June 2019. "Samsung 50nm 2GB DDR3 chips are industry's smallest". SlashGear. 29 September 2008. Retrieved 25 June 2019. "History: 2010s". az5miao. Retrieved 4 April 2022. "Our Proud Heritage from 2010 to Now". Samsung Semiconductor. Samsung. Retrieved 25 June 2019. "Samsung Electronics Announces Industry's First 8Gb LPDDR5 DRAM for 5G and AI-powered Mobile Applications". Samsung. July 17, 2018. Retrieved 8 July 2019. "Samsung Unleashes a Roomy DDR4 256GB RAM". Tom's Hardware. 6 September 2018. Archived from the original on June 21, 2019. Retrieved 4 April 2022. HM5283206 Datasheet. Hitachi. 11 November 1994. Retrieved 10 July 2019. "Hitachi HM5283206FP10 8Mbit SGRAM" (PDF). Smithsonian Institution. Archived (PDF) from the original on 2003-07-16. Retrieved 10 July 2019. μPD481850 Datasheet. NEC. 6 December 1994. Retrieved 10 July 2019. NEC Application Specific Memory. NEC. Fall 1995. p. 359. Retrieved 21 June 2019. UPD4811650 Datasheet. NEC. December 1997. Retrieved 10 July 2019. Takeuchi, Kei (1998). "16M-BIT SYNCHRONOUS GRAPHICS RAM: μPD4811650". NEC Device Technology International (48). Retrieved 10 July 2019. "Samsung Announces the World's First 222 MHz 32Mbit SGRAM for 3D Graphics and Networking Applications". Samsung Semiconductor. Samsung. 12 July 1999. Retrieved 10 July 2019. "Samsung Electronics Announces JEDEC-Compliant 256Mb GDDR2 for 3D Graphics". Samsung Electronics. Samsung. 28 August 2003. Retrieved 26 June 2019. "K4D553238F Datasheet". Samsung Electronics. March 2005. Retrieved 10 July 2019. "Samsung Electronics Develops Industry's First Ultra-Fast GDDR4 Graphics DRAM". Samsung Semiconductor. Samsung. October 26, 2005. Retrieved 8 July 2019. "K4W1G1646G-BC08 Datasheet" (PDF). Samsung Electronics. November 2010. Archived (PDF) from the original on 2022-01-24. Retrieved 10 July 2019. Shilov, Anton (March 29, 2016). "Micron Begins to Sample GDDR5X Memory, Unveils Specs of Chips". AnandTech. Retrieved 16 July 2019. Shilov, Anton (July 19, 2017). "Samsung Increases Production Volumes of 8 GB HBM2 Chips Due to Growing Demand". AnandTech. Retrieved 29 June 2019. "HBM". Samsung Semiconductor. Samsung. Retrieved 16 July 2019. "Samsung Electronics Starts Producing Industry's First 16-Gigabit GDDR6 for Advanced Graphics Systems". Samsung. January 18, 2018. Retrieved 15 July 2019. Killian, Zak (18 January 2018). "Samsung fires up its foundries for mass production of GDDR6 memory". Tech Report. Retrieved 18 January 2018. "Samsung Begins Producing The Fastest GDDR6 Memory In The World". Wccftech. 18 January 2018. Retrieved 16 July 2019. Media related to RAM at Wikimedia Commons