Grosch's law is the following observation of computer performance, made by Herb Grosch in 1953: I believe that there is a fundamental rule, which I modestly call Grosch's law, giving added economy only as the square root of the increase in speed — that is, to do a calculation ten times as cheaply you must do it hundred times as fast. This adage is more commonly stated as Computer performance increases as the square of the cost. If computer A costs twice as much as computer B, you should expect computer A to be four times as fast as computer B. Two years before Grosch's statement, Seymour Cray was quoted in Business Week (August 1963) expressing this very same thought: Computers should obey a square law — when the price doubles, you should get at least four times as much speed. The law can also be interpreted as meaning that computers present economies of scale: the more costly is the computer, the price–performance ratio linearly becomes better. This implies that low-cost computers cannot compete in the market. An analysis of rental cost/performance data for computers between 1951 and 1963 by Kenneth E. Knight found that Grosch's law held for commercial and scientific operations (a modern analysis of the same data found that Grosch's law only applied to commercial operations). In a separate study, Knight found that Grosch's law did not apply to computers between 1963-1967 (also confirmed by the aforementioned modern analysis).