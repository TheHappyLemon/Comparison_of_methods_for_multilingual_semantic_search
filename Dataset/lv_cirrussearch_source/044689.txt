Mākslīgais neironu tīkls, MNT (angļu: artificial neural network, ANN) ir datorsistēma, kas veidota, iedvesmojoties no neironu tīkla, kāds ir dzīvnieku smadzenēs. Mākslīgais neironu tīkls pats par sevi nav algoritms, bet gan daudzu dažādu mašīnmācīšanās algoritmu ietvars, kur kopdarbā tiek apstrādāti sarežģīti ievades dati. Šādas sistēmas "iemācās" veikt uzdevumus pēc apmācības piemēriem; parasti netiekot programmētas ar uzdevumam specifiskiem noteikumiem. Piemēram, attēlu atpazīšanā MNT var iemācīties identificēt attēlus, kas satur kaķus, analizējot piemēra attēlus, kas manuāli apzīmēti kā "ir kaķis" vai "nav kaķa", un, izmantojot apmācības rezultātus, spētu identificēt kaķus citos attēlos ar augstu varbūtību. Mākslīgie neironu tīkli to dara bez jebkādām iepriekšējām zināšanām par kaķiem, piemēram, par to, ka tiem ir kažoks, aste, ūsas un kaķiem līdzīgas sejas. Tā vietā tie automātiski ģenerē identificējošās pazīmes no mācību materiāla, ko tie apstrādā. Mākslīgo neironu tīklu pamatā ir savienotu vienību jeb mezglu, sauktu par mākslīgajiem neironiem, kopums, kas vienkāršoti modelē neironus bioloģiskajās smadzenēs. Katrs savienojums, līdzīgi kā dzīvnieku smadzeņu sinapses, var pārraidīt signālu no viena neirona uz citu. Mākslīgais neirons, kas saņem signālu, var to apstrādāt un pēc tam nodot signālu papildu mākslīgajiem neironiem, kas tam pievienoti. MNT vispārējās realizācijās signāls savienojumā starp mākslīgajiem neironiem ir reāls skaitlis, un katra mākslīgā neirona izvade tiek aprēķināta pēc kādas nelineāras funkcijas no tā ievades summas. Savienojumus starp mākslīgajiem neironiem sauc par "šķautnēm" (edges). Mākslīgajiem neironiem un šķautnēm parasti ir svars, kas piemērojas, mācoties. Svars palielina vai samazina signāla stiprumu savienojumā. Mākslīgajiem neironiem var būt tāds slieksnis, ka signāls tiek nosūtīts tikai tad, ja kopsummas signāls šķērso šo slieksni. Parasti mākslīgie neironi tiek sakopoti slāņos. Dažādi slāņi var veikt dažāda veida transformācijas ar to ievadēm. Signāli pārvietojas no pirmā slāņa (ievades slāņa) uz pēdējo slāni (izvades slāni), iespējams, pēc tam caur slāņiem var pārvietoties vairākas reizes. Mākslīgo neironu tīklu pieejas sākotnējais mērķis bija atrisināt problēmas tādā pašā veidā, kā to darītu cilvēka smadzenes. Laika gaitā tomēr uzmanība tika pievērsta konkrētu uzdevumu veikšanai, novirzoties no bioloģijas. Mākslīgie nervu tīkli tiek izmantoti dažādos uzdevumos, tostarp datorredze, runas atpazīšana, mašīntulkošana, sociālo tīklu filtrēšana, galda un datorspēļu spēlēšana un medicīniskā diagnostika. Neirons ar apzīmējumu j {\displaystyle j} , kas saņem ievadi p j ( t ) {\displaystyle p_{j}(t)} no priekšgājēju neironiem, sastāv no šādiem komponentiem: aktivizācija a j ( t ) {\displaystyle a_{j}(t)} , neirona stāvoklis, atkarībā no diskrēta laika parametra, iespējams, slieksnis θ j {\displaystyle \theta _{j}} , kas paliek nemainīgs, ja vien to nemaina mācīšanas funkcija, aktivizācijas funkcija f {\displaystyle f} , kas aprēķina jauno aktivizāciju dotajā laikā t + 1 {\displaystyle t+1} no a j ( t ) {\displaystyle a_{j}(t)} , θ j {\displaystyle \theta _{j}} un tīkla ievade p j ( t ) {\displaystyle p_{j}(t)} , kas rada attiecību a j ( t + 1 ) = f ( a j ( t ) , p j ( t ) , θ j ) {\displaystyle a_{j}(t+1)=f(a_{j}(t),p_{j}(t),\theta _{j})} , izvades funkcija f o u t {\displaystyle f_{out}} , aprēķina izvadi no aktivizācijas o j ( t ) = f o u t ( a j ( t ) ) {\displaystyle o_{j}(t)=f_{out}(a_{j}(t))} . Bieži izvades funkcija ir tikai identiskā funkcija. Ievades neironam nav priekšteča, bet tas kalpo kā visa tīkla ievades saskarne. Līdzīgi izvades neironam nav pēcteča un tādējādi kalpo kā visa tīkla izvades saskarne. Tīkls sastāv no savienojumiem, katrs savienojums pārvieto neirona i {\displaystyle i} izvadi uz neirona j {\displaystyle j} ievadi. Šajā nozīmē i {\displaystyle i} ir j {\displaystyle j} priekštecis, un j {\displaystyle j} ir i {\displaystyle i} pēctecis. Katram savienojumam tiek piešķirts svars w i j {\displaystyle w_{ij}} . Dažreiz ievades vērtību kopējai svērtajai summai tiek pievienota nobīde, kas kalpo par slieksni, lai mainītu aktivizācijas funkciju. Izplatīšanas funkcija izskaitļo ievadi p j ( t ) {\displaystyle p_{j}(t)} neironam j {\displaystyle j} no priekšteču neironu izvades o i ( t ) {\displaystyle o_{i}(t)} un parasti ir formā p j ( t ) = ∑ i o i ( t ) w i j {\displaystyle p_{j}(t)=\sum _{i}o_{i}(t)w_{ij}} . Ja funkcijai tiek pievienota nobīdes vērtība, iepriekšminētā forma mainās uz šādu p j ( t ) = ∑ i o i ( t ) w i j + w 0 j {\displaystyle p_{j}(t)=\sum _{i}o_{i}(t)w_{ij}+w_{0j}} , kur w 0 j {\displaystyle w_{0j}} ir nobīde. Mācīšanās noteikums ir noteikums vai algoritms, kas maina neironu tīkla parametrus, lai dotā ievade tīklā radītu vēlamo izvadi. Šī mācīšanā apstrādā parasti vērtības, lai mainītu tīkla mainīgo lielumu svarus un sliekšņus. Neironu tīkla modeļus var skatīt kā vienkāršus matemātiskus modeļus, kas definē funkciju f : X → Y {\displaystyle \textstyle f:X\rightarrow Y} vai sadalījumu virs X {\displaystyle \textstyle X} vai gan X {\displaystyle \textstyle X} gan Y {\displaystyle \textstyle Y} . Dažkārt modeļi ir cieši saistīti ar daļējiem mācīšanās noteikumiem. Bieži lietojama frāze "MNT modelis" patiesībā ir šādu funkciju klases definīcija (kur klases elementi tiek iegūti ar dažādiem parametriem, savienojuma svariem vai arhitektūras specifikām, piemēram, neironu skaitu vai to savienojamību). Matemātiski neironu tīkla funkcija f ( x ) {\displaystyle \textstyle f(x)} ir definēta kā citu funkciju kompozīcija g i ( x ) {\displaystyle \textstyle g_{i}(x)} , ko tālāk var sadalīt citās funkcijās. To var ērti attēlot kā tīkla struktūru ar bultiņām, kas attēlo atkarību starp funkcijām. Plaši lietotais kompozīcijas tips ir nelineāri svērta summa, kur f ( x ) = K ( ∑ i w i g i ( x ) ) {\displaystyle \textstyle f(x)=K\left(\sum _{i}w_{i}g_{i}(x)\right)} , kur K {\displaystyle \textstyle K} (parasti attiecināts kā aktivācijas funkcija) ir kāda iepriekšdefinēta funkcoija, piemēram, Hiperboliskais tangenss, signoīda funkcija, softmax funkcija vai taisngrieža funkcija. Aktivācijas funkcijas svarīga iezīme ir tā, ka, mainoties ievades vērtībām, tā nodrošina vienmērīgu pāreju, t.i., nelielas izmaiņas ievadē rada nelielas izmaiņas izvadē. Šī funkcija attiecas uz funkciju kolekciju g i {\displaystyle \textstyle g_{i}} kā vektoru g = ( g 1 , g 2 , … , g n ) {\displaystyle \textstyle g=(g_{1},g_{2},\ldots ,g_{n})} . Zīmējumā pa labi ir attēlota šāda f {\displaystyle \textstyle f} dekompozīcija ar atkarībām starp mainīgajiem, kas apzīmēti ar bultiņām. Tos var interpretēt divējādi. Pirmais skats ir funkcionālais skats: ievade x {\displaystyle \textstyle x} ir pārveidota par trīsdimensiju vektoru h {\displaystyle \textstyle h} , kas pēc tam tiek pārveidots par divdimensiju vektoru g {\displaystyle \textstyle g} , kas visbeidzot pārveidots par f {\displaystyle \textstyle f} . Šis skats visbiežāk sastopams optimizācijas kontekstā. Otrais skats ir varbūtiskais skats: gadījuma mainīgais F = f ( G ) {\displaystyle \textstyle F=f(G)} ir atkarīgs no gadījuma mainīgā G = g ( H ) {\displaystyle \textstyle G=g(H)} , kas ir atkarīgs no H = h ( X ) {\displaystyle \textstyle H=h(X)} , kas ir atkarīgs no gadījuma mainīgā X {\displaystyle \textstyle X} . Šis skats visbiežāk sastopams grafu modeļa kontekstā. Abi skati lielākoties ir līdzvērtīgi. Jebkurā gadījumā šai konkrētajai arhitektūrai atsevišķu slāņu komponenti ir neatkarīgi viens no otra (piemēram, g {\displaystyle \textstyle g} komponenti ir neatkarīgi viens no otra, ņemot vērā to ievades h {\displaystyle \textstyle h} ). Sistēmas realizācijā tas dabiskā veidā dod iespēju īstenot paralēlismu. Tādus tīklus kā iepriekšējais parasti sauc par apsteidzošajiem, jo to grafs ir virzīts aciklisks grafs. Tīklus ar cikliem parasti sauc par rekurentajiem. Šādi tīkli parasti tiek attēloti tā, kā parādīts attēla augšpusē, kur f {\displaystyle \textstyle f} tiek parādīts kā atkarīgs pats no sevis. Tomēr netieša īslaicīga atkarība netiek parādīta. «Build with AI | DeepAI». DeepAI. Arhivēts no oriģināla, laiks: 2018-10-06. Skatīts: 2018-10-06. Abbod, Maysam F (2007). "Application of Artificial Intelligence to the Management of Urological Cancer". The Journal of Urology 178 (4): 1150–1156. doi:10.1016/j.juro.2007.05.122. PMID 17698099. DAWSON, CHRISTIAN W (1998). "An artificial neural network approach to rainfall-runoff modelling". Hydrological Sciences Journal 43 (1): 47–66. doi:10.1080/02626669809492102. «The Machine Learning Dictionary». Arhivēts no oriģināla, laiks: 2018. gada 26. augustā. Skatīts: 2019. gada 27. februārī.